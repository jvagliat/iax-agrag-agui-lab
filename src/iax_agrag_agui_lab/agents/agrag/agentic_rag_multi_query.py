"""
üîç Agentic RAG System - Multi-Query Version
Sistema de RAG con Triage ‚Üí Query Generation ‚Üí Multi-Retrieval ‚Üí Synthesis
Usando OpenAI y estrategia multi-query inspirada en sistema legal
"""

from google.adk.agents import LlmAgent, SequentialAgent
from google.adk.tools import FunctionTool
from typing import Any

from agents.agrag.query_docs_tool import query_iax_documentation_rag
from google.adk.models.lite_llm import LiteLlm

# ==================== HERRAMIENTAS ====================
vector_search_tool = FunctionTool(
    func=query_iax_documentation_rag,
)

# ==================== AGENTES ====================

# 1Ô∏è‚É£ TRIAGE AGENT - Clasifica consultas (usando OpenAI)
triage_agent = LlmAgent(
    name="TriageAgent",
    model=LiteLlm(model="openai/gpt-4.1-mini"),
    description="Clasifica consultas del usuario: GENERAL o SPECIFIC",
    instruction="""
    Eres un asistente que clasifica consultas de usuarios sobre iattraxia y la plataforma IAX.

    Analiza la pregunta del usuario y determina:

    - **GENERAL**: Saludos, preguntas simples, conversaci√≥n casual, agradecimientos
      Ejemplos: "hola", "¬øc√≥mo est√°s?", "gracias", "¬øqu√© puedes hacer?", "buenos d√≠as"

    - **SPECIFIC**: Preguntas espec√≠ficas sobre:
      * iattraxia (la empresa, servicios, equipo)
      * Plataforma IAX (funcionalidades, arquitectura, uso)
      * Desarrollo de software con IA
      * Agentes aut√≥nomos o automatizaciones
      * Tecnolog√≠as relacionadas

    **Si es GENERAL**: Responde directamente de forma amigable y breve. Pres√©ntate como
    asistente especializado en iattraxia/IAX y ofrece ayuda.

    **Si es SPECIFIC**: Di algo como "D√©jame buscar esa informaci√≥n en la documentaci√≥n..."
    y luego USA transfer_to_agent para llamar a 'QueryGeneratorAgent'.

    S√© conversacional y amigable.
    """,
    output_key="triage_result",
    sub_agents=[]  # Se configurar√° despu√©s
)


# 2Ô∏è‚É£ QUERY GENERATOR - Genera m√∫ltiples consultas diversas
query_generator_agent = LlmAgent(
    name="QueryGeneratorAgent",
    model=LiteLlm(model="openai/gpt-4.1-mini"),
    description="Genera 3 consultas de b√∫squeda diversas para maximizar cobertura",
    instruction="""
    Eres un experto en formulaci√≥n de consultas de b√∫squeda.

    El usuario pregunt√≥: (lee el mensaje del usuario)

    **Tu trabajo**:
    Genera EXACTAMENTE 3 consultas de b√∫squeda diferentes para buscar informaci√≥n relevante.
    Las consultas deben ser:
    - **Diversas**: Enfocar diferentes aspectos de la pregunta
    - **Espec√≠ficas**: Usar t√©rminos t√©cnicos relevantes (IAX, iattraxia, agentes, automatizaci√≥n, etc.)
    - **Complementarias**: Cubrir diferentes √°ngulos de la misma necesidad

    **Formato de salida**:
    Devuelve SOLO las 3 consultas, una por l√≠nea, sin numeraci√≥n ni explicaciones adicionales.

    Ejemplo de salida esperada:
    funcionalidades de la plataforma IAX
    arquitectura y componentes del sistema IAX
    casos de uso de agentes aut√≥nomos en IAX

    Despu√©s de generar las consultas, USA transfer_to_agent para llamar a 'MultiRetrievalAgent'.
    """,
    output_key="generated_queries",
    sub_agents=[]  # Se configurar√° despu√©s
)


# 3Ô∏è‚É£ MULTI-RETRIEVAL AGENT - Ejecuta b√∫squedas con las 3 consultas
multi_retrieval_agent = LlmAgent(
    name="MultiRetrievalAgent",
    model=LiteLlm(model="openai/gpt-4.1-mini"),
    description="Ejecuta b√∫squedas vectoriales con las consultas generadas",
    instruction="""
    Eres un experto en recuperaci√≥n de informaci√≥n.

    Las consultas generadas est√°n en: {generated_queries}

    **Tu trabajo**:
    1. Lee las 3 consultas generadas
    2. USA la herramienta `vector_search` con CADA una de las 3 consultas
    3. Recopila todos los resultados obtenidos
    4. Si obtienes resultados relevantes, transfiere a 'SynthesizerAgent' con transfer_to_agent
    5. Si no encuentras nada √∫til en ninguna consulta, d√≠selo al usuario educadamente

    **Importante**:
    - Ejecuta las 3 b√∫squedas aunque algunas den resultados
    - Los resultados combinados dar√°n mejor cobertura al Synthesizer
    """,
    output_key="retrieved_chunks",
    tools=[vector_search_tool],
    sub_agents=[]  # Se configurar√° despu√©s
)


# 4Ô∏è‚É£ SYNTHESIZER AGENT - Genera respuesta final con citas
synthesizer_agent = LlmAgent(
    name="SynthesizerAgent",
    model=LiteLlm(model="openai/gpt-4.1-mini"),
    description="Genera respuesta final integrando informaci√≥n de m√∫ltiples b√∫squedas",
    instruction="""
    Eres un redactor t√©cnico experto especializado en iattraxia y la plataforma IAX.

    El usuario pregunt√≥: (lee el mensaje original del usuario)
    Los chunks recuperados de m√∫ltiples b√∫squedas est√°n en: {retrieved_chunks}

    **Tu trabajo**:
    1. Lee cuidadosamente TODOS los chunks recuperados de las diferentes consultas
    2. Identifica informaci√≥n complementaria y elimina redundancias
    3. Genera una respuesta clara, coherente y bien estructurada
    4. CITA las fuentes usando formato: üìö **Fuentes**: [fuente1], [fuente2]
    5. Si la informaci√≥n es parcial o hay lagunas, ind√≠calo expl√≠citamente
    6. Usa tono profesional pero accesible

    **Formato de respuesta**:
    - Usa **markdown** con vi√±etas, negritas para t√©rminos clave
    - Estructura l√≥gica: introducci√≥n ‚Üí puntos principales ‚Üí informaci√≥n complementaria
    - Citas distribuidas en el texto cuando sea relevante
    - Secci√≥n final "üìö **Fuentes**:" con lista de documentos consultados

    **Reglas estrictas**:
    - NO inventes informaci√≥n que no est√© en los chunks
    - Si m√∫ltiples chunks contradicen, menciona ambas perspectivas
    - Adapta longitud seg√∫n complejidad (1 p√°rrafo a 5 p√°rrafos m√°ximo)
    - Si no hay suficiente informaci√≥n, adm√≠telo y sugiere reformular la pregunta
    """,
    output_key="final_response"
)


# ==================== CONFIGURACI√ìN DE SUB-AGENTES ====================

# Pipeline: Query Generation ‚Üí Multi-Retrieval ‚Üí Synthesis
research_pipeline = SequentialAgent(
    name="ResearchPipeline",
    # instruction="Cada vez que avances en la secuencia ve USANDO transfer_to_agent al siguiente agente.",
    sub_agents=[query_generator_agent, multi_retrieval_agent, synthesizer_agent]
)

# Triage tiene acceso al pipeline completo
triage_agent.sub_agents = [research_pipeline]


# ==================== AGENTE PRINCIPAL ====================

agentic_rag_multi_query_bot = triage_agent
