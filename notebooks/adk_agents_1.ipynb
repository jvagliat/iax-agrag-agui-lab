{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee468a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af32b9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83710874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "# langfuse = Langfuse(\n",
    "#   secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "#   public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "#   host=os.getenv(\"LANGFUSE_HOST\")\n",
    "# )\n",
    "langfuse = Langfuse(\n",
    "  secret_key=\"sk-lf-6ce5f05d-8a04-45cf-9515-97c213299fa1\",\n",
    "  public_key=\"pk-lf-01bf2b5e-1d2e-4aaa-9821-51501f9638a2\",\n",
    "  host=\"https://us.cloud.langfuse.com\"\n",
    ")\n",
    "\n",
    "#langfuse.log_event(\"notebook_started\", {\"status\": \"started\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c386afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-CN9PPJNFDOzKex3qqtmdtEqcyf8kn', created=1759633747, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_f33640a400', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready! How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=27, total_tokens=40, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      "OpenAI is ready for use.\n"
     ]
    }
   ],
   "source": [
    "# Define Model Constants for easier use \n",
    "MODEL_GPT = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, \n",
    "                                messages=[{\"role\": \"user\", \n",
    "                                           \"content\": \"Are you ready?\"}], \n",
    "                                tools=[]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3850a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3155a14",
   "metadata": {},
   "source": [
    "## 3.2. Explore `neo4j_for_adk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d72a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97002a1",
   "metadata": {},
   "source": [
    "graphdb has a method send_query which expects a cypher query, runs the query and then formats the results as follows:\n",
    "\n",
    "<img src=\"images/send_query_expln.png\" alt=\"diagram of the send_query method from the graphdb module showing success or failure response to a query\" width=400>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45660f7c",
   "metadata": {},
   "source": [
    "# Sending a simple query to the database\n",
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22209a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a basic tool -- send a parameterized cypher query\n",
    "def say_hello(person_name: str) -> dict:\n",
    "    \"\"\"Formats a welcome message to a named person. \n",
    "\n",
    "    Args:\n",
    "        person_name (str): the name of the person saying hello\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the results of the query.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'query_result' key with an array of result rows.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    return graphdb.send_query(\"RETURN 'Hello to you, ' + $person_name AS reply\",\n",
    "    {\n",
    "        \"person_name\": person_name\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'hello_agent_v1' created.\n"
     ]
    }
   ],
   "source": [
    "# Define the Cypher Agent\n",
    "hello_agent = Agent(\n",
    "    name=\"hello_agent_v1\",\n",
    "    model=llm, # defined earlier in a variable\n",
    "    description=\"Has friendly chats with a user.\",\n",
    "    instruction=\"\"\"You are a helpful assistant, chatting with a user. \n",
    "                Be polite and friendly, introducing yourself and asking who the user is. \n",
    "\n",
    "                If the user provides their name, use the 'say_hello' tool to get a custom greeting.\n",
    "                If the tool returns an error, inform the user politely. \n",
    "                If the tool is successful, present the reply.\n",
    "\n",
    "                Always respond in markdown format.\n",
    "                \"\"\",\n",
    "    tools=[say_hello], # Pass the function directly\n",
    ")\n",
    "\n",
    "print(f\"Agent '{hello_agent.name}' created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7b5f92",
   "metadata": {},
   "source": [
    "## 3.5. Run the Agent \n",
    "To run an agent, you'll need some additional components namely an execution environment and memory.\n",
    "### 3.5.1. Event Loop    \n",
    "\n",
    "<img src=\"images/event_loop_3.png\"  alt=\"diagram of Agent Development Kit runtime showing the Runner component handling an Event Loop with Services for the User\" width=800> \n",
    "\n",
    "The [ADK Runtime](https://google.github.io/adk-docs/runtime/) orchestrates agents throughout execution. The main component is an event-driven loop intermediated by a Runner. When the runner receives a user query, it asks the agent to start processing. The agent processes the query and emits an event. The Runner receives the event, records state changes, updates memory and forwards the event to the user interface. After that, the agent's logic resumes and the cycle repeats until no further events are produced by the agent and the user has a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca3ccac7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LlmAgent' object has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mhello_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mHello, who are you?\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pablo\\git\\iax-agrag-agui-lab\\venv\\Lib\\site-packages\\pydantic\\main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'LlmAgent' object has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "hello_agent.chat(\"Hello, who are you?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
